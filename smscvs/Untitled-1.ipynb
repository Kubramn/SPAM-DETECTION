{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longest_capital_char_count(sms):\n",
    "  longest = 0\n",
    "  current_longest = 0\n",
    "  for char in sms:\n",
    "    if char.isupper():\n",
    "      current_longest += 1\n",
    "      if longest < current_longest:\n",
    "        longest = current_longest\n",
    "    else:\n",
    "      current_longest = 0\n",
    "  return longest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_capital_char_count(sms):\n",
    "  total_capital_letters = 0\n",
    "  previous_char_capital = False\n",
    "  count = 0\n",
    "  for char in sms:\n",
    "    if char.isupper():\n",
    "      total_capital_letters += 1\n",
    "      previous_char_capital = True\n",
    "    else:\n",
    "      if(previous_char_capital):\n",
    "        count += 1\n",
    "        previous_char_capital = False\n",
    "  if char.isupper() and previous_char_capital:\n",
    "    count += 1\n",
    "  if count == 0 or total_capital_letters == 0:\n",
    "    return 0\n",
    "  else:\n",
    "    result = total_capital_letters / count\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_capital_char_count(sms):\n",
    "  total = 0\n",
    "  for char in sms:\n",
    "    if char.isupper():\n",
    "      total += 1\n",
    "  result = total\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage_capital_char(sms):\n",
    "  if len(sms) == 0:\n",
    "    return 0 \n",
    "  total = total_capital_char_count(sms)\n",
    "  result = total / len(sms)\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocess(message):\n",
    "    # Remove punctuations\n",
    "    nopunc = [char for char in message if char not in string.punctuation]\n",
    "\n",
    "    # Join the characters again\n",
    "    nopunc = \"\".join(nopunc)\n",
    "    nopunc = nopunc.lower()\n",
    "\n",
    "    # Remove any stopwords and non-alphabetic characters\n",
    "    nostop = [\n",
    "        word\n",
    "        for word in nopunc.split()\n",
    "        if word.lower() not in stopwords.words(\"english\") and word.isalpha()\n",
    "    ]\n",
    "\n",
    "    return nostop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = pd.read_csv(\"spam.csv\", encoding=\"utf-8\")\n",
    "messages =messages.get([\"label\", \"message\"])\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longest_capital_char_count</th>\n",
       "      <th>average_capital_char_count</th>\n",
       "      <th>total_capital_char_count</th>\n",
       "      <th>percentage_capital_char</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_:</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_]</th>\n",
       "      <th>char_freq_)</th>\n",
       "      <th>...</th>\n",
       "      <th>reply</th>\n",
       "      <th>urgent</th>\n",
       "      <th>ur</th>\n",
       "      <th>please</th>\n",
       "      <th>nokia</th>\n",
       "      <th>new</th>\n",
       "      <th>service</th>\n",
       "      <th>get</th>\n",
       "      <th>contact</th>\n",
       "      <th>stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.769024</td>\n",
       "      <td>1.213160</td>\n",
       "      <td>5.564250</td>\n",
       "      <td>0.066374</td>\n",
       "      <td>0.137114</td>\n",
       "      <td>0.132807</td>\n",
       "      <td>0.020998</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.088658</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027997</td>\n",
       "      <td>0.013101</td>\n",
       "      <td>0.204594</td>\n",
       "      <td>0.024587</td>\n",
       "      <td>0.012922</td>\n",
       "      <td>0.033381</td>\n",
       "      <td>0.014178</td>\n",
       "      <td>0.095477</td>\n",
       "      <td>0.013460</td>\n",
       "      <td>0.031048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.990362</td>\n",
       "      <td>0.657129</td>\n",
       "      <td>11.130837</td>\n",
       "      <td>0.109094</td>\n",
       "      <td>0.782739</td>\n",
       "      <td>0.469444</td>\n",
       "      <td>0.145872</td>\n",
       "      <td>0.035436</td>\n",
       "      <td>0.035436</td>\n",
       "      <td>0.364510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179567</td>\n",
       "      <td>0.119866</td>\n",
       "      <td>0.532343</td>\n",
       "      <td>0.158316</td>\n",
       "      <td>0.136019</td>\n",
       "      <td>0.184574</td>\n",
       "      <td>0.121233</td>\n",
       "      <td>0.323552</td>\n",
       "      <td>0.115245</td>\n",
       "      <td>0.200354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       longest_capital_char_count  average_capital_char_count  \\\n",
       "count                 5572.000000                 5572.000000   \n",
       "mean                     1.769024                    1.213160   \n",
       "std                      1.990362                    0.657129   \n",
       "min                      0.000000                    0.000000   \n",
       "25%                      1.000000                    1.000000   \n",
       "50%                      1.000000                    1.000000   \n",
       "75%                      1.000000                    1.000000   \n",
       "max                     18.000000                    9.500000   \n",
       "\n",
       "       total_capital_char_count  percentage_capital_char  char_freq_;  \\\n",
       "count               5572.000000              5572.000000  5572.000000   \n",
       "mean                   5.564250                 0.066374     0.137114   \n",
       "std                   11.130837                 0.109094     0.782739   \n",
       "min                    0.000000                 0.000000     0.000000   \n",
       "25%                    1.000000                 0.025974     0.000000   \n",
       "50%                    2.000000                 0.038462     0.000000   \n",
       "75%                    4.000000                 0.062500     0.000000   \n",
       "max                  128.000000                 1.000000    36.000000   \n",
       "\n",
       "       char_freq_:  char_freq_(  char_freq_[  char_freq_]  char_freq_)  ...  \\\n",
       "count  5572.000000  5572.000000  5572.000000  5572.000000  5572.000000  ...   \n",
       "mean      0.132807     0.020998     0.000897     0.000897     0.088658  ...   \n",
       "std       0.469444     0.145872     0.035436     0.035436     0.364510  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "max       7.000000     2.000000     2.000000     2.000000     6.000000  ...   \n",
       "\n",
       "             reply       urgent           ur       please        nokia  \\\n",
       "count  5572.000000  5572.000000  5572.000000  5572.000000  5572.000000   \n",
       "mean      0.027997     0.013101     0.204594     0.024587     0.012922   \n",
       "std       0.179567     0.119866     0.532343     0.158316     0.136019   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       2.000000     2.000000     7.000000     2.000000     2.000000   \n",
       "\n",
       "               new      service          get      contact         stop  \n",
       "count  5572.000000  5572.000000  5572.000000  5572.000000  5572.000000  \n",
       "mean      0.033381     0.014178     0.095477     0.013460     0.031048  \n",
       "std       0.184574     0.121233     0.323552     0.115245     0.200354  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "max       2.000000     2.000000     3.000000     1.000000     3.000000  \n",
       "\n",
       "[8 rows x 63 columns]"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_number_pattern = re.compile(r\"\\d{4,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = re.compile(r'(http(s)?:\\/\\/)?([\\w-]+\\.)+[\\w-]+(\\/[.\\/?%&=]*)?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = [\";\",\":\",\"(\",\"[\",\"]\",\")\",\"!\",\"#\",\"£\",\"...\",\"<\",\">\",\"-\",\"_\",\"?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = [\n",
    "\"Thanks for your subscription\",\n",
    "\"Congarts\",\n",
    "\"Congratulations\",\n",
    "\"you are awarded\",\n",
    "\"you have WON\",\n",
    "\"You are a winner\",\n",
    "\" U have been specially selected\",\n",
    "\"URGENT\",\n",
    "\"FreeMsg\",\n",
    "\"FREE\",\n",
    "\"Today's Offer\",\n",
    "\"customer service announcement\",\n",
    "\"Send STOP\",\n",
    "\"Please CALL -numbers-\",\n",
    "\"Give us a call\",\n",
    "\"Final Chance!\",\n",
    "\"Valentines Day Special\",\n",
    "\"we tried to contact you\",\n",
    "\"Last Chance\",\n",
    "\"This message is free\",\n",
    "\"Txt CHAT to\",\n",
    "\"WELL DONE\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages['longest_capital_char_count'] = messages.apply(lambda row: longest_capital_char_count(row.message), axis=1)\n",
    "messages['average_capital_char_count'] = messages.apply(lambda row: average_capital_char_count(row.message), axis=1)\n",
    "messages['total_capital_char_count'] = messages.apply(lambda row: total_capital_char_count(row.message), axis=1)\n",
    "messages['percentage_capital_char'] = messages.apply(lambda row: percentage_capital_char(row.message), axis=1)\n",
    "\n",
    "for char in chars:\n",
    "  key = f\"char_freq_{char}\"\n",
    "  messages[key] =  messages.apply(lambda row: row.message.count(char), axis=1)\n",
    "\n",
    "\"\"\"\n",
    "messages['char_freq_;'] = messages.apply(lambda row: row.message.count(\";\"), axis=1)\n",
    "messages['char_freq_('] = messages.apply(lambda row: row.message.count(\"(\"), axis=1)\n",
    "messages['char_freq_['] = messages.apply(lambda row: row.message.count(\"[\"), axis=1)\n",
    "messages['char_freq_['] = messages.apply(lambda row: row.message.count(\"{\"), axis=1)\n",
    "messages['char_freq_!'] = messages.apply(lambda row: row.message.count(\"!\"), axis=1)\n",
    "messages['char_freq_#'] = messages.apply(lambda row: row.message.count(\"#\"), axis=1)\n",
    "messages['char_freq_$'] = messages.apply(lambda row: row.message.count(\"$\"), axis=1)\n",
    "messages['char_freq_£'] = messages.apply(lambda row: row.message.count(\"£\"), axis=1)\n",
    "messages['char_freq_...'] = messages.apply(lambda row: row.message.count(\"...\"), axis=1)\n",
    "\"\"\"\n",
    "\n",
    "for i in range(len(phrases)):\n",
    "  key = f\"sentence{i}\"\n",
    "  messages[key] =  messages.apply(lambda row: row.message.count(phrases[i]), axis=1)\n",
    "\n",
    "\n",
    "messages['big_number_count'] = messages['message'].apply(lambda x: len(re.findall(big_number_pattern,x)))\n",
    "messages['urls_count'] = messages['message'].apply(lambda x: len(re.findall(urls, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>longest_capital_char_count</th>\n",
       "      <th>average_capital_char_count</th>\n",
       "      <th>total_capital_char_count</th>\n",
       "      <th>percentage_capital_char</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_:</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>...</th>\n",
       "      <th>sentence14</th>\n",
       "      <th>sentence15</th>\n",
       "      <th>sentence16</th>\n",
       "      <th>sentence17</th>\n",
       "      <th>sentence18</th>\n",
       "      <th>sentence19</th>\n",
       "      <th>sentence20</th>\n",
       "      <th>sentence21</th>\n",
       "      <th>big_number_count</th>\n",
       "      <th>urls_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.25</td>\n",
       "      <td>10</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...   \n",
       "1   ham                      Ok lar... Joking wif u oni...   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3   ham  U dun say so early hor... U c already then say...   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "   longest_capital_char_count  average_capital_char_count  \\\n",
       "0                           1                        1.00   \n",
       "1                           1                        1.00   \n",
       "2                           2                        1.25   \n",
       "3                           1                        1.00   \n",
       "4                           1                        1.00   \n",
       "\n",
       "   total_capital_char_count  percentage_capital_char  char_freq_;  \\\n",
       "0                         3                 0.027027            0   \n",
       "1                         2                 0.068966            0   \n",
       "2                        10                 0.064516            0   \n",
       "3                         2                 0.040816            0   \n",
       "4                         2                 0.032787            0   \n",
       "\n",
       "   char_freq_:  char_freq_(  char_freq_[  ...  sentence14  sentence15  \\\n",
       "0            0            0            0  ...           0           0   \n",
       "1            0            0            0  ...           0           0   \n",
       "2            0            1            0  ...           0           0   \n",
       "3            0            0            0  ...           0           0   \n",
       "4            0            0            0  ...           0           0   \n",
       "\n",
       "   sentence16  sentence17  sentence18  sentence19  sentence20  sentence21  \\\n",
       "0           0           0           0           0           0           0   \n",
       "1           0           0           0           0           0           0   \n",
       "2           0           0           0           0           0           0   \n",
       "3           0           0           0           0           0           0   \n",
       "4           0           0           0           0           0           0   \n",
       "\n",
       "   big_number_count  urls_count  \n",
       "0                 0           0  \n",
       "1                 0           0  \n",
       "2                 3           0  \n",
       "3                 0           0  \n",
       "4                 0           0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>longest_capital_char_count</th>\n",
       "      <th>average_capital_char_count</th>\n",
       "      <th>total_capital_char_count</th>\n",
       "      <th>percentage_capital_char</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_:</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>...</th>\n",
       "      <th>sentence14</th>\n",
       "      <th>sentence15</th>\n",
       "      <th>sentence16</th>\n",
       "      <th>sentence17</th>\n",
       "      <th>sentence18</th>\n",
       "      <th>sentence19</th>\n",
       "      <th>sentence20</th>\n",
       "      <th>sentence21</th>\n",
       "      <th>big_number_count</th>\n",
       "      <th>urls_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>[free, entry, wkly, comp, win, fa, cup, final,...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.25</td>\n",
       "      <td>10</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[nah, dont, think, goes, usf, lives, around, t...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  \\\n",
       "0   ham  [go, jurong, point, crazy, available, bugis, n...   \n",
       "1   ham                     [ok, lar, joking, wif, u, oni]   \n",
       "2  spam  [free, entry, wkly, comp, win, fa, cup, final,...   \n",
       "3   ham      [u, dun, say, early, hor, u, c, already, say]   \n",
       "4   ham  [nah, dont, think, goes, usf, lives, around, t...   \n",
       "\n",
       "   longest_capital_char_count  average_capital_char_count  \\\n",
       "0                           1                        1.00   \n",
       "1                           1                        1.00   \n",
       "2                           2                        1.25   \n",
       "3                           1                        1.00   \n",
       "4                           1                        1.00   \n",
       "\n",
       "   total_capital_char_count  percentage_capital_char  char_freq_;  \\\n",
       "0                         3                 0.027027            0   \n",
       "1                         2                 0.068966            0   \n",
       "2                        10                 0.064516            0   \n",
       "3                         2                 0.040816            0   \n",
       "4                         2                 0.032787            0   \n",
       "\n",
       "   char_freq_:  char_freq_(  char_freq_[  ...  sentence14  sentence15  \\\n",
       "0            0            0            0  ...           0           0   \n",
       "1            0            0            0  ...           0           0   \n",
       "2            0            1            0  ...           0           0   \n",
       "3            0            0            0  ...           0           0   \n",
       "4            0            0            0  ...           0           0   \n",
       "\n",
       "   sentence16  sentence17  sentence18  sentence19  sentence20  sentence21  \\\n",
       "0           0           0           0           0           0           0   \n",
       "1           0           0           0           0           0           0   \n",
       "2           0           0           0           0           0           0   \n",
       "3           0           0           0           0           0           0   \n",
       "4           0           0           0           0           0           0   \n",
       "\n",
       "   big_number_count  urls_count  \n",
       "0                 0           0  \n",
       "1                 0           0  \n",
       "2                 3           0  \n",
       "3                 0           0  \n",
       "4                 0           0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove punctuations/stopwords from all messages\n",
    "nltk.download('stopwords')\n",
    "messages[\"message\"] = messages[\"message\"].apply(text_preprocess)\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>longest_capital_char_count</th>\n",
       "      <th>average_capital_char_count</th>\n",
       "      <th>total_capital_char_count</th>\n",
       "      <th>percentage_capital_char</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_:</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>...</th>\n",
       "      <th>sentence14</th>\n",
       "      <th>sentence15</th>\n",
       "      <th>sentence16</th>\n",
       "      <th>sentence17</th>\n",
       "      <th>sentence18</th>\n",
       "      <th>sentence19</th>\n",
       "      <th>sentence20</th>\n",
       "      <th>sentence21</th>\n",
       "      <th>big_number_count</th>\n",
       "      <th>urls_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entry wkly comp win fa cup final tkts may...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.25</td>\n",
       "      <td>10</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah dont think goes usf lives around though</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  \\\n",
       "0   ham  go jurong point crazy available bugis n great ...   \n",
       "1   ham                            ok lar joking wif u oni   \n",
       "2  spam  free entry wkly comp win fa cup final tkts may...   \n",
       "3   ham                u dun say early hor u c already say   \n",
       "4   ham        nah dont think goes usf lives around though   \n",
       "\n",
       "   longest_capital_char_count  average_capital_char_count  \\\n",
       "0                           1                        1.00   \n",
       "1                           1                        1.00   \n",
       "2                           2                        1.25   \n",
       "3                           1                        1.00   \n",
       "4                           1                        1.00   \n",
       "\n",
       "   total_capital_char_count  percentage_capital_char  char_freq_;  \\\n",
       "0                         3                 0.027027            0   \n",
       "1                         2                 0.068966            0   \n",
       "2                        10                 0.064516            0   \n",
       "3                         2                 0.040816            0   \n",
       "4                         2                 0.032787            0   \n",
       "\n",
       "   char_freq_:  char_freq_(  char_freq_[  ...  sentence14  sentence15  \\\n",
       "0            0            0            0  ...           0           0   \n",
       "1            0            0            0  ...           0           0   \n",
       "2            0            1            0  ...           0           0   \n",
       "3            0            0            0  ...           0           0   \n",
       "4            0            0            0  ...           0           0   \n",
       "\n",
       "   sentence16  sentence17  sentence18  sentence19  sentence20  sentence21  \\\n",
       "0           0           0           0           0           0           0   \n",
       "1           0           0           0           0           0           0   \n",
       "2           0           0           0           0           0           0   \n",
       "3           0           0           0           0           0           0   \n",
       "4           0           0           0           0           0           0   \n",
       "\n",
       "   big_number_count  urls_count  \n",
       "0                 0           0  \n",
       "1                 0           0  \n",
       "2                 3           0  \n",
       "3                 0           0  \n",
       "4                 0           0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert messages (as lists of string tokens) to strings\n",
    "messages[\"message\"] = messages[\"message\"].agg(lambda x: \" \".join(map(str, x)))\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [397], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m vectorizer \u001b[39m=\u001b[39m CountVectorizer(max_features\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m)\n\u001b[0;32m      3\u001b[0m spam_messages \u001b[39m=\u001b[39m messages[messages[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m'\u001b[39m\u001b[39mspam\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m----> 5\u001b[0m spam_bagOfWords_matrix \u001b[39m=\u001b[39m vectorizer\u001b[39m.\u001b[39;49mfit_transform(spam_messages)\n\u001b[0;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m vectorizer\u001b[39m.\u001b[39mvocabulary_\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m      8\u001b[0m   messages[word] \u001b[39m=\u001b[39m  messages\u001b[39m.\u001b[39mapply((\u001b[39mlambda\u001b[39;00m row: row\u001b[39m.\u001b[39mmessage\u001b[39m.\u001b[39mcount(word)), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\feature_extraction\\text.py:1377\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1369\u001b[0m             warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1370\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mUpper case characters found in\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1371\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m vocabulary while \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlowercase\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1372\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m is True. These entries will not\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1373\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m be matched with any documents\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1374\u001b[0m             )\n\u001b[0;32m   1375\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m-> 1377\u001b[0m vocabulary, X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_count_vocab(raw_documents, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfixed_vocabulary_)\n\u001b[0;32m   1379\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbinary:\n\u001b[0;32m   1380\u001b[0m     X\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mfill(\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\feature_extraction\\text.py:1283\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1281\u001b[0m     vocabulary \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(vocabulary)\n\u001b[0;32m   1282\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m vocabulary:\n\u001b[1;32m-> 1283\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1284\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mempty vocabulary; perhaps the documents only contain stop words\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1285\u001b[0m         )\n\u001b[0;32m   1287\u001b[0m \u001b[39mif\u001b[39;00m indptr[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m>\u001b[39m np\u001b[39m.\u001b[39miinfo(np\u001b[39m.\u001b[39mint32)\u001b[39m.\u001b[39mmax:  \u001b[39m# = 2**31 - 1\u001b[39;00m\n\u001b[0;32m   1288\u001b[0m     \u001b[39mif\u001b[39;00m _IS_32BIT:\n",
      "\u001b[1;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "# Initialize count vectorizer\n",
    "vectorizer = CountVectorizer(max_features=20)\n",
    "spam_messages = messages[messages['label']=='spam'][\"message\"]\n",
    "\n",
    "spam_bagOfWords_matrix = vectorizer.fit_transform(spam_messages)\n",
    "\n",
    "for word in vectorizer.vocabulary_.keys():\n",
    "  messages[word] =  messages.apply((lambda row: row.message.count(word)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>longest_capital_char_count</th>\n",
       "      <th>average_capital_char_count</th>\n",
       "      <th>total_capital_char_count</th>\n",
       "      <th>percentage_capital_char</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_:</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>...</th>\n",
       "      <th>reply</th>\n",
       "      <th>urgent</th>\n",
       "      <th>ur</th>\n",
       "      <th>please</th>\n",
       "      <th>nokia</th>\n",
       "      <th>new</th>\n",
       "      <th>service</th>\n",
       "      <th>get</th>\n",
       "      <th>contact</th>\n",
       "      <th>stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>free entry wkly comp win fa cup final tkts may...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.25</td>\n",
       "      <td>10</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>nah dont think goes usf lives around though</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  \\\n",
       "0     0  go jurong point crazy available bugis n great ...   \n",
       "1     0                            ok lar joking wif u oni   \n",
       "2     1  free entry wkly comp win fa cup final tkts may...   \n",
       "3     0                u dun say early hor u c already say   \n",
       "4     0        nah dont think goes usf lives around though   \n",
       "\n",
       "   longest_capital_char_count  average_capital_char_count  \\\n",
       "0                           1                        1.00   \n",
       "1                           1                        1.00   \n",
       "2                           2                        1.25   \n",
       "3                           1                        1.00   \n",
       "4                           1                        1.00   \n",
       "\n",
       "   total_capital_char_count  percentage_capital_char  char_freq_;  \\\n",
       "0                         3                 0.027027            0   \n",
       "1                         2                 0.068966            0   \n",
       "2                        10                 0.064516            0   \n",
       "3                         2                 0.040816            0   \n",
       "4                         2                 0.032787            0   \n",
       "\n",
       "   char_freq_:  char_freq_(  char_freq_[  ...  reply  urgent  ur  please  \\\n",
       "0            0            0            0  ...      0       0   1       0   \n",
       "1            0            0            0  ...      0       0   0       0   \n",
       "2            0            1            0  ...      0       0   0       0   \n",
       "3            0            0            0  ...      0       0   0       0   \n",
       "4            0            0            0  ...      0       0   0       0   \n",
       "\n",
       "   nokia  new  service  get  contact  stop  \n",
       "0      0    0        0    0        0     0  \n",
       "1      0    0        0    0        0     0  \n",
       "2      0    0        0    0        0     0  \n",
       "3      0    0        0    0        0     0  \n",
       "4      0    0        0    0        0     0  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert spam and ham labels to 0 and 1 (or, vice-versa)\n",
    "messages.loc[messages[\"label\"] == \"spam\", \"label\"] = 1\n",
    "messages.loc[messages[\"label\"] == \"ham\", \"label\"] = 0\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.to_csv(\"evaluated_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a97dfee85535fb1d5b47fe9558cac8ab9061198b8187c5e3fe351ac320e8c61d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
